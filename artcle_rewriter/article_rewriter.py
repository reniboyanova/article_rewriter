import torch
import requests
from openai import OpenAI
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from scraper import Scraper
from utils.utils import load_json, get_api_key

PROMPTS = load_json("./prompts.json").get('prompts', [])

class AIRewriter:
    def __init__(self, src_url, prompts_list) -> None:
        self.__scraper = None
        
        try:
            self.__scraper =  Scraper(src_url)
        except Exception as e:
            raise Exception(f"Error from Scraper, self.__scraper can not be set of exception: {e}")
        
        if self.__scraper is not None:
            self.__scraper.extract_data()
            self.data = self.__scraper.data
        
        self.prompts = prompts_list
        if not self.prompts:
            print("List with prompts is empty, please list at least one prompt!")
            self.prompts = list(input())
            
        self.__api_key = get_api_key('./OPEN_AI_API_KET.txt')
            
        
    def gpt_rewriter(self, max_len=4096) -> dict:
        client = OpenAI(api_key=self.__api_key)
        
        title = self.data.get('title', '')
        anonse = self.data.get('anonse', '')
        article_text = self.data.get('article_text', '')
        
        results = {}

        for index, prompt in enumerate(self.prompts):
            title_prompt = f"{prompt}\n\nRewrite the title:\n{title}"
            anonse_prompt = f"{prompt}\n\nRewrite the subtitle (anonse):\n{anonse}"
            text_prompt = f"{prompt}\n\nRewrite the article text:\n{article_text}"

            # Request for the rewritten title
            chat_completion_title = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "You are a skilled content writer who creates human-like articles."},
                    {"role": "user", "content": title_prompt}
                ],
                model="gpt-4o",
                max_tokens=max_len,
                temperature=0.8
            )
            
            rewritten_title = chat_completion_title.choices[0].message.content.strip()

            # Request for the rewritten anonse
            chat_completion_subtitle = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "You are a skilled content writer who creates human-like articles."},
                    {"role": "user", "content": anonse_prompt}
                ],
                model="gpt-4o",
                max_tokens=max_len,
                temperature=0.8
            )
            
            rewritten_anonse = chat_completion_subtitle.choices[0].message.content.strip()

            # Request for the rewritten article text
            chat_completion_text = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "You are a skilled content writer who creates human-like articles."},
                    {"role": "user", "content": text_prompt}
                ],
                model="gpt-4o",
                max_tokens=max_len,
                temperature=0.8
            )
            
            rewritten_article_text = chat_completion_text.choices[0].message.content.strip()
            
            results[index] = {
                'title': rewritten_title,
                'anonse': rewritten_anonse,
                'text': rewritten_article_text
            }
        
        return results
    
    
    def ai_detector(self, text) -> float:
        model_name = "roberta-base-openai-detector"  # for gpt-2, but after tries with text, generated by gpt-4o makes good results
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        
        inputs = tokenizer(text, return_tensors="pt", truncation=True)
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=-1)

        return probs[0][1].item() * 100
    
    
    def get_ai_detection_edenai(self, text):
        api_url = "https://api.edenai.run/v2/text/ai_detection"
        api_key = get_api_key('./EDENAI_API_KEY.txt')
        headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
        }

        data = {
            "text": text,
            "providers": "originalityai,winstonai"
        }
        
        response = requests.post(api_url, json=data, headers=headers)

        if response.status_code == 200:
            result = response.json()

            originalityai_result = result.get('originalityai')
            
            if originalityai_result and originalityai_result.get('status') == 'success':
                prediction = originalityai_result['items'][0].get('prediction')
                ai_score = originalityai_result['items'][0].get('ai_score')
                return {"prediction": prediction, "ai_score": ai_score}
            else:
                return {"error": "No valid result from OriginalityAI"}
        else:
            return {"error": f"API request failed with status code {response.status_code}"}

            
        
        