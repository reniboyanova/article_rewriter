import os

import requests

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer


class AIDetector:
    @staticmethod
    def ai_detector(text) -> float:
        model_name = "roberta-base-openai-detector"  # for gpt-2, but after tries with text, generated by gpt-4o makes good results
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)

        inputs = tokenizer(text, return_tensors="pt", truncation=True)
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=-1)

        return probs[0][1].item() * 100

    @staticmethod
    def get_ai_detection_edenai(text):
        api_url = "https://api.edenai.run/v2/text/ai_detection"
        headers = {
            "Authorization": f"Bearer {os.getenv('EDENAI_API_BEARER_TOKEN')}",
            "Content-Type": "application/json"
        }

        data = {
            "text": text,
            "providers": "originalityai,winstonai"
        }

        response = requests.post(api_url, json=data, headers=headers)

        if response.status_code == 200:
            result = response.json()

            originalityai_result = result.get('originalityai')

            if originalityai_result and originalityai_result.get('status') == 'success':
                prediction = originalityai_result['items'][0].get('prediction')
                ai_score = originalityai_result['items'][0].get('ai_score')
                return {"prediction": prediction, "ai_score": ai_score}
            else:
                return None
        else:
            return None
